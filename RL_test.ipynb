{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pari0\\anaconda3\\envs\\simulator\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:211: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym(\"CartPole-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n",
      "c:\\Users\\pari0\\anaconda3\\envs\\simulator\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "c:\\Users\\pari0\\anaconda3\\envs\\simulator\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Loss: 1.02150559425354\n",
      "Episode: 100, Loss: 1.0225005149841309\n",
      "Episode: 200, Loss: 1.023775577545166\n",
      "Episode: 300, Loss: 1.3533390760421753\n",
      "Episode: 400, Loss: 1.0166887044906616\n",
      "Episode: 500, Loss: 1.0237770080566406\n",
      "Episode: 600, Loss: 1.0226658582687378\n",
      "Episode: 700, Loss: 1.022606611251831\n",
      "Episode: 800, Loss: 1.0236257314682007\n",
      "Episode: 900, Loss: 1.0228310823440552\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Neural Network for Q-learning\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "gamma = 0.99  # discount factor\n",
    "epsilon = 0.1  # exploration rate\n",
    "num_episodes = 1000\n",
    "\n",
    "# Environment setup\n",
    "env = gym.make('CartPole-v1')\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "\n",
    "# Q-Network\n",
    "net = QNetwork(input_size, 64, output_size)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "frames = []\n",
    "\n",
    "\n",
    "# Training loop\n",
    "# Training loop\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()  # Unpack the state to ignore the dictionary\n",
    "    done = False\n",
    "    loss = None  # Initialize loss\n",
    "\n",
    "    while not done:\n",
    "        frames.append(env.render())\n",
    "        state_tensor = torch.FloatTensor([state]).view(1, -1)\n",
    "        with torch.no_grad():\n",
    "            q_values = net(state_tensor)\n",
    "\n",
    "        # Epsilon-greedy strategy\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample()  # Explore\n",
    "        else:\n",
    "            action = torch.argmax(q_values).item()  # Exploit\n",
    "\n",
    "        # Take action\n",
    "        step_output = env.step(action)\n",
    "        try:\n",
    "            next_state, reward, done, _, _ = step_output  # Adjust unpacking for extra element\n",
    "        except ValueError as e:\n",
    "            print(f\"Error unpacking step output: {e}\")\n",
    "            break\n",
    "\n",
    "        next_state_tensor = torch.FloatTensor([next_state]).view(1, -1)\n",
    "        with torch.no_grad():\n",
    "            next_q_values = net(next_state_tensor)\n",
    "\n",
    "        # Ensure q_target has the same shape as q_val\n",
    "        q_target = reward + gamma * torch.max(next_q_values).detach()  # Detach target from graph\n",
    "        q_val = q_values.gather(1, torch.tensor([[action]], device=q_values.device))  # Ensure q_val is part of the graph and has the correct shape\n",
    "\n",
    "        q_target.requires_grad_(True)\n",
    "        q_val.requires_grad_(True)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(q_val, q_target.unsqueeze(-1))  # Make sure both tensors have the same shape\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    if episode % 100 == 0 and loss is not None:\n",
    "        print(f'Episode: {episode}, Loss: {loss.item()}')\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# matplotlib 설정\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# GPU를 사용할 경우\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simulator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
